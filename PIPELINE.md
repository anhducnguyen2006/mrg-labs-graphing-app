# MRG Labs Graphing App - Project Pipeline

## ğŸ”„ Data Flow Architecture

This document outlines the complete pipeline of how data flows through the MRG Labs FTIR Graphing Application, from user interaction to final visualization and AI analysis.

---

## ğŸ“Š High-Level Pipeline Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Browser   â”‚
â”‚  (React App)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Frontend Layer                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  1. Authentication & Routing     â”‚  â”‚
â”‚  â”‚  2. File Upload & Validation     â”‚  â”‚
â”‚  â”‚  3. Data Visualization           â”‚  â”‚
â”‚  â”‚  4. AI Chat Interface            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ HTTP/REST API
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Backend Layer (FastAPI)         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  1. Session Management           â”‚  â”‚
â”‚  â”‚  2. File Processing              â”‚  â”‚
â”‚  â”‚  3. Graph Generation             â”‚  â”‚
â”‚  â”‚  4. AI Analysis Services         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â–¼         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MySQL  â”‚ â”‚ Google Geminiâ”‚
â”‚Database â”‚ â”‚   AI API     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” Stage 1: User Authentication Pipeline

### 1.1 Signup Flow

```
User fills signup form
    â†“
Frontend validates input (email format, password strength)
    â†“
POST /register â†’ Backend
    â†“
Backend validates data
    â†“
Check if email exists in MySQL
    â†“
If new: Hash password with bcrypt
    â†“
Insert user into `users` table
    â†“
Create session, set cookie
    â†“
Return success + user data
    â†“
Frontend stores auth state in AuthContext
    â†“
Redirect to Dashboard
```

**Technologies:**
- Frontend: React + Chakra UI forms, React Context API
- Backend: FastAPI, bcrypt, MySQL
- Security: bcrypt (12 rounds), SQL parameterization

---

### 1.2 Login Flow

```
User enters credentials
    â†“
POST /login â†’ Backend
    â†“
Query user by email from MySQL
    â†“
Verify password with bcrypt.checkpw()
    â†“
If valid: Create session with UUID
    â†“
Store session in `sessions` table (user_id, expires_at)
    â†“
Set httpOnly cookie with session_id
    â†“
Return user data (no password)
    â†“
Frontend updates AuthContext
    â†“
Redirect to Dashboard
```

**Session Management:**
- Session expires after 7 days
- httpOnly cookies prevent XSS attacks
- Sessions stored in MySQL with expiration timestamps

---

### 1.3 Protected Routes

```
User navigates to protected page
    â†“
React Router checks AuthContext
    â†“
If not authenticated:
    â†“
    Redirect to /login
    â†“
If authenticated:
    â†“
    Every API request includes session cookie
    â†“
    Backend validates session via @require_auth decorator
    â†“
    Check session exists in DB and not expired
    â†“
    If valid: Proceed with request
    â†“
    If invalid: Return 401 Unauthorized
```

---

## ğŸ“ Stage 2: File Upload & Processing Pipeline

### 2.1 Baseline Upload

```
User clicks "Upload Baseline"
    â†“
Browser file picker opens
    â†“
User selects CSV file
    â†“
Frontend reads file with FileReader API
    â†“
Papa Parse parses CSV to JSON
    â†“
Validate structure:
  - Check for X and Y columns
  - Verify numeric data
  - Minimum data points (e.g., 100)
    â†“
Store in React state as ParsedCSV object:
  {
    filename: string,
    x: number[],
    y: number[]
  }
    â†“
Display filename in UI
    â†“
Enable "Upload Samples" button
```

**Key Libraries:**
- `Papa Parse`: CSV parsing
- React state hooks: Data management

---

### 2.2 Sample Files Upload

```
User clicks "Upload Samples"
    â†“
Browser file picker (multiple=true)
    â†“
User selects multiple CSV files
    â†“
For each file:
    â†“
    Read with FileReader
    â†“
    Parse with Papa Parse
    â†“
    Validate structure (same as baseline)
    â†“
    Store in samples array with ParsedCSV format
    â†“
Display all samples in sidebar:
  - Filename
  - Data point count
  - Interactive selection
```

---

## ğŸ“Š Stage 3: Graph Visualization Pipeline

### 3.1 Interactive Chart Generation

```
User selects a sample from sidebar
    â†“
Frontend triggers useEffect with [baseline, selectedSample]
    â†“
Prepare Chart.js data structure:
  {
    datasets: [
      {
        label: baseline.filename,
        data: baseline.x.map((x, i) => ({x, y: baseline.y[i]})),
        borderColor: 'blue',
        borderWidth: 2
      },
      {
        label: sample.filename,
        data: sample.x.map((x, i) => ({x, y: sample.y[i]})),
        borderColor: 'red',
        borderWidth: 2
      }
    ]
  }
    â†“
Configure Chart.js options:
  - Responsive: true
  - Scales: linear X and Y axes
  - Plugins: zoom, pan, legend
  - Tooltips: show (x, y) coordinates
    â†“
Render with react-chartjs-2
    â†“
User can:
  - Zoom with mouse wheel
  - Pan by dragging
  - Reset view with button
  - Toggle gridlines
```

**Visualization Stack:**
- Chart.js: Core charting library
- react-chartjs-2: React wrapper
- chartjs-plugin-zoom: Interactive zoom/pan

---

### 3.2 FTIR Analysis & Scoring

```
User uploads samples
    â†“
For each sample, calculate difference from baseline:
    â†“
    Interpolate baseline and sample to common X points
    â†“
    Calculate delta: Î´ = baseline_y - sample_y
    â†“
    Apply scoring method (user-selectable):
    â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Method 1: RMSE Deviation            â”‚
    â”‚   RMSE = âˆš(Î£(w_i Ã— Î´_iÂ²) / Î£(w_i)) â”‚
    â”‚   Score based on thresholds         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Method 2: Hybrid (RMSE + Shape)     â”‚
    â”‚   Base Score = f(RMSE)              â”‚
    â”‚   Pearson Penalty = g(correlation)  â”‚
    â”‚   Final = Base - Penalty            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Method 3: Area Difference           â”‚
    â”‚   Area = Î£(w Ã— dx Ã— |Î´y|)           â”‚
    â”‚   Trapezoidal integration           â”‚
    â”‚   Score based on total area         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Assign anomaly score (0-100, higher = better)
    â†“
Display score badge next to filename:
  - 90-100: Green (Excellent)
  - 70-89: Yellow (Good)
  - <70: Red (Critical)
    â†“
Update sidebar with color-coded scores
```

**Scoring Features:**
- Wavelength-based weights (oxidation zone: 200%, fingerprint: 100%)
- Real-time score updates
- Visual heatmap of deviations
- Method comparison tooltips

---

### 3.3 Deviation Heatmap

```
Calculate deviations for selected sample
    â†“
For each X point:
    â†“
    deviation = weight Ã— |baseline_y - sample_y|
    â†“
    (method-specific: RMSE uses Î´Â², others use |Î´|)
    â†“
Normalize to 0-1 range for color mapping
    â†“
Map to color gradient:
  - Green (0.0-0.3): Low deviation
  - Yellow (0.3-0.7): Medium deviation
  - Red (0.7-1.0): High deviation
    â†“
Render horizontal color bar below graph
    â†“
User hovers to see exact deviation value
```

---

## ğŸ¤– Stage 4: AI Analysis Pipeline

### 4.1 Automated Graph Insights

```
User clicks "Analyze with AI" button
    â†“
Frontend gathers context:
  - Baseline filename
  - Sample filename
  - Score from current method
  - Graph data statistics (min, max, mean, std)
    â†“
POST /analysis/generate_insights
    â†“
Backend prepares prompt for Gemini AI:
  """
  Analyze this FTIR spectroscopy comparison:
  - Baseline: {baseline_name}
  - Sample: {sample_name}
  - Anomaly Score: {score}/100
  - Statistical data: {stats}
  
  Provide:
  1. Key findings
  2. Trend analysis
  3. Anomaly detection
  4. Recommendations
  """
    â†“
Send to Google Gemini API (gemini-1.5-flash)
    â†“
Gemini processes request (temperature=0.7)
    â†“
Return structured JSON:
  {
    "summary": "Overall assessment...",
    "key_findings": ["Finding 1", "Finding 2"],
    "trends": "Identified patterns...",
    "anomalies": "Detected issues...",
    "recommendations": ["Action 1", "Action 2"]
  }
    â†“
Backend returns to frontend
    â†“
Display in expandable card with sections:
  - Summary badge
  - Key findings list
  - Detailed analysis
  - Action recommendations
```

**AI Configuration:**
- Model: gemini-1.5-flash
- Temperature: 0.7 (balanced creativity)
- Max tokens: 1024
- Timeout: 30 seconds

---

### 4.2 Chatbot Interaction

```
User types question in chatbot
    â†“
Frontend captures message + conversation history
    â†“
POST /chat/send_message
  {
    "message": "What does this peak mean?",
    "conversation_history": [
      {"role": "user", "content": "Previous question"},
      {"role": "assistant", "content": "Previous answer"}
    ],
    "graph_context": {
      "baseline": "...",
      "sample": "...",
      "score": 85
    }
  }
    â†“
Backend constructs conversation with context:
    â†“
    System prompt: "You are an FTIR spectroscopy expert..."
    â†“
    Include graph context in first message
    â†“
    Append conversation history
    â†“
    Add user's new question
    â†“
Send to Gemini API with chat session
    â†“
Gemini generates contextual response
    â†“
Return response to frontend
    â†“
Display in chat bubble with:
  - User message (right-aligned, blue)
  - AI response (left-aligned, gray)
  - Timestamp
  - Markdown rendering
    â†“
Update conversation history
    â†“
Ready for next question
```

**Chat Features:**
- Context-aware responses
- Conversation memory
- Scientific terminology
- Code/formula rendering with Markdown
- Copy response button

---

## ğŸ“¤ Stage 5: Export Pipeline

### 5.1 Graph Generation (Backend)

```
User clicks "Export Graphs"
    â†“
Frontend collects all samples
    â†“
POST /generate_graphs
  {
    "baseline": {x: [...], y: [...]},
    "samples": [{x: [...], y: [...]}, ...],
    "user_id": 123
  }
    â†“
Backend receives request (requires auth)
    â†“
For each sample:
    â†“
    Create matplotlib figure (10Ã—6 inches, 300 DPI)
    â†“
    Plot baseline: plt.plot(baseline.x, baseline.y, 'b-', linewidth=2)
    â†“
    Plot sample: plt.plot(sample.x, sample.y, 'r-', linewidth=2)
    â†“
    Add labels:
      - X-axis: "Wavenumber (cmâ»Â¹)"
      - Y-axis: "Absorbance (A)"
      - Title: "Baseline vs {sample_name}"
    â†“
    Add legend with filenames
    â†“
    Add grid with alpha=0.3
    â†“
    Save to PNG:
      backend/static/generated_graphs/{run_id}/{sample_name}.png
    â†“
Collect all PNG paths
    â†“
Create ZIP archive:
  FTIR_export.zip
    â”œâ”€â”€ sample1_vs_baseline.png
    â”œâ”€â”€ sample2_vs_baseline.png
    â””â”€â”€ ...
    â†“
Store metadata in MySQL `files` table:
  - user_id
  - original_filenames
  - generated_paths
  - timestamp
    â†“
Return ZIP file to frontend
```

**Export Technologies:**
- Matplotlib: Graph rendering
- Pillow: Image processing
- zipfile: Archive creation
- Python pathlib: File management

---

### 5.2 Frontend Export Handling

#### Option A: Standard Download

```
User clicks "Export" button
    â†“
Browser receives ZIP blob
    â†“
Create download link:
  <a href={blob_url} download="FTIR_export.zip">
    â†“
    Programmatic click triggers download
    â†“
    ZIP saved to Downloads folder
    â†“
    Show success notification
```

#### Option B: Folder Selection (Chromium Only)

```
User clicks "Export to Folder" button
    â†“
Check if window.showDirectoryPicker exists
    â†“
If yes (Chrome/Edge):
    â†“
    Prompt user to select folder
    â†“
    await window.showDirectoryPicker()
    â†“
    User grants write permission
    â†“
    Get file handle:
      handle = await directoryHandle.getFileHandle('FTIR_export.zip', {create: true})
    â†“
    Create writable stream
    â†“
    Write ZIP blob to stream
    â†“
    Close stream
    â†“
    Success: File written to chosen folder
    â†“
If no (Firefox/Safari):
    â†“
    Button disabled
    â†“
    Fallback to standard download
```

**Browser Support:**
- âœ… Chrome 86+
- âœ… Edge 86+
- âœ… Opera 72+
- âŒ Firefox
- âŒ Safari

---

## ğŸ—„ï¸ Stage 6: Database Pipeline

### 6.1 User Data Flow

```sql
-- On Signup
INSERT INTO users (email, password_hash, created_at)
VALUES (?, ?, NOW());

-- On Login
SELECT id, email, password_hash
FROM users
WHERE email = ?;

-- Session Creation
INSERT INTO sessions (session_id, user_id, expires_at)
VALUES (UUID(), ?, DATE_ADD(NOW(), INTERVAL 7 DAY));

-- Session Validation
SELECT s.user_id, u.email
FROM sessions s
JOIN users u ON s.user_id = u.id
WHERE s.session_id = ? AND s.expires_at > NOW();

-- File Tracking
INSERT INTO files (user_id, original_filenames, generated_paths, created_at)
VALUES (?, ?, ?, NOW());
```

### 6.2 Database Schema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            users                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)          INT AUTO_INCREMENT  â”‚
â”‚ email            VARCHAR(255) UNIQUE â”‚
â”‚ password_hash    VARCHAR(255)        â”‚
â”‚ created_at       DATETIME            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â”‚ 1:N
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          sessions                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)          INT AUTO_INCREMENT  â”‚
â”‚ session_id       VARCHAR(255) UNIQUE â”‚
â”‚ user_id (FK)     INT                 â”‚
â”‚ expires_at       DATETIME            â”‚
â”‚ created_at       DATETIME            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                â”‚
                â”‚ 1:N
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            files                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)              INT             â”‚
â”‚ user_id (FK)         INT             â”‚
â”‚ original_filenames   TEXT            â”‚
â”‚ generated_paths      TEXT            â”‚
â”‚ created_at           DATETIME        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Deployment Pipeline (Docker)

### Build Process

```bash
# 1. Build Docker images
docker compose build
    â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Frontend (Node Alpine)         â”‚
    â”‚  - npm install dependencies     â”‚
    â”‚  - npm run build (Vite)         â”‚
    â”‚  - Serve with nginx:1.25-alpine â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Backend (Python 3.11 Slim)     â”‚
    â”‚  - pip install requirements     â”‚
    â”‚  - uvicorn FastAPI server       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# 2. Start containers
docker compose up
    â†“
    Frontend container: Port 5173
    Backend container: Port 8080
    MySQL container: Port 3306 (internal)
    â†“
    Network bridge connects all services
    â†“
    Volume mounts:
      - ./backend/static â†’ /app/static (persistent graphs)
      - mysql-data â†’ /var/lib/mysql (persistent DB)
```

### Container Communication

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Docker Network: mrg-labs-network       â”‚
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚  Frontend     â”‚                     â”‚
â”‚  â”‚  nginx:5173   â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚          â”‚ HTTP proxy                  â”‚
â”‚          â–¼                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Backend      â”‚â”€â”€â”€â”€â–¶â”‚   MySQL    â”‚  â”‚
â”‚  â”‚  uvicorn:8080 â”‚     â”‚   :3306    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚          â”‚                              â”‚
â”‚          â–¼                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚ Google Gemini â”‚ (external API)      â”‚
â”‚  â”‚     AI        â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Complete End-to-End Example

### Scenario: New User Analyzes FTIR Data

```
1. USER REGISTRATION
   â”œâ”€ Navigate to /signup
   â”œâ”€ Enter: email@example.com, password123
   â”œâ”€ Frontend: POST /register
   â”œâ”€ Backend: Hash password, insert to MySQL
   â”œâ”€ Backend: Create session, set cookie
   â””â”€ Frontend: Redirect to /dashboard

2. FILE UPLOAD
   â”œâ”€ Click "Upload Baseline"
   â”œâ”€ Select baseline.csv (3451 data points)
   â”œâ”€ Papa Parse: Convert to {x: [...], y: [...]}
   â”œâ”€ Validate: All numeric, sufficient points âœ“
   â”œâ”€ Display: "baseline.csv uploaded"
   â”œâ”€ Click "Upload Samples"
   â”œâ”€ Select sample1.csv, sample2.csv, sample3.csv
   â”œâ”€ Parse and validate all samples âœ“
   â””â”€ Display: 3 samples in sidebar

3. INTERACTIVE VISUALIZATION
   â”œâ”€ Click sample1.csv in sidebar
   â”œâ”€ React: useEffect triggers chart update
   â”œâ”€ Chart.js: Render baseline (blue) + sample1 (red)
   â”œâ”€ Calculate FTIR scores:
   â”‚   â”œâ”€ Hybrid method selected
   â”‚   â”œâ”€ RMSE = 0.15 â†’ Base Score = 78
   â”‚   â”œâ”€ Pearson r = 0.97 â†’ No penalty
   â”‚   â””â”€ Final Score = 78 (Yellow badge)
   â”œâ”€ Render deviation heatmap (mostly green, some yellow)
   â”œâ”€ User: Zoom into 1700-1750 cmâ»Â¹ (oxidation zone)
   â””â”€ User: Toggle grid, adjust view

4. AI ANALYSIS
   â”œâ”€ Click "Analyze with AI"
   â”œâ”€ Frontend: POST /analysis/generate_insights
   â”œâ”€ Backend: Construct prompt with graph context
   â”œâ”€ Gemini API: Process analysis (3 seconds)
   â”œâ”€ Return: {
   â”‚     summary: "Moderate oxidation detected",
   â”‚     key_findings: ["Peak at 1720 cmâ»Â¹", "Score: 78/100"],
   â”‚     recommendations: ["Monitor sample", "Consider relubrication"]
   â”‚   }
   â””â”€ Display: Expandable insight card with findings

5. CHATBOT INTERACTION
   â”œâ”€ Open chatbot sidebar
   â”œâ”€ User types: "What does the peak at 1720 mean?"
   â”œâ”€ Frontend: POST /chat/send_message + graph context
   â”œâ”€ Backend: Send to Gemini with conversation history
   â”œâ”€ Gemini: Generate contextual response
   â”œâ”€ Response: "The peak at 1720 cmâ»Â¹ indicates carbonyl..."
   â”œâ”€ Display: Chat bubble with markdown
   â”œâ”€ User asks follow-up: "Is this critical?"
   â””â”€ AI responds with context-aware answer

6. EXPORT GRAPHS
   â”œâ”€ Click "Export Graphs"
   â”œâ”€ Frontend: POST /generate_graphs with all samples
   â”œâ”€ Backend: Generate 3 PNG graphs with matplotlib
   â”‚   â”œâ”€ sample1_vs_baseline.png
   â”‚   â”œâ”€ sample2_vs_baseline.png
   â”‚   â””â”€ sample3_vs_baseline.png
   â”œâ”€ Backend: Create FTIR_export.zip
   â”œâ”€ Backend: Store metadata in MySQL files table
   â”œâ”€ User clicks "Export to Folder" (Chrome)
   â”œâ”€ Browser: showDirectoryPicker() â†’ User selects Desktop
   â”œâ”€ Write ZIP to Desktop/FTIR_export.zip
   â””â”€ Success notification: "Exported 3 graphs to Desktop"

7. LOGOUT
   â”œâ”€ Click profile menu â†’ Logout
   â”œâ”€ Frontend: POST /logout
   â”œâ”€ Backend: Delete session from database
   â”œâ”€ Backend: Clear session cookie
   â”œâ”€ Frontend: Clear AuthContext
   â””â”€ Redirect to /login
```

---

## ğŸ› ï¸ Technology Stack Summary

### Frontend Pipeline

| Stage | Technology | Purpose |
|-------|------------|---------|
| UI Framework | React 18 + TypeScript | Component-based architecture |
| Routing | React Router v6 | SPA navigation |
| State Management | React Context API | Global auth state |
| UI Components | Chakra UI | Accessible, themed components |
| Charting | Chart.js + react-chartjs-2 | Interactive graphs |
| CSV Parsing | Papa Parse | Fast CSV processing |
| File System | File System Access API | Custom folder exports |
| Build Tool | Vite | Fast HMR, optimized builds |
| HTTP Client | Fetch API | REST communication |

### Backend Pipeline

| Stage | Technology | Purpose |
|-------|------------|---------|
| API Framework | FastAPI | High-performance Python API |
| Auth | bcrypt | Password hashing |
| Session Management | MySQL + UUID | Secure session storage |
| Database | MySQL 8.0 | User & file data |
| Graph Generation | Matplotlib + Pandas | Scientific visualization |
| Image Processing | Pillow | PNG optimization |
| AI Integration | Google Gemini API | Analysis & chat |
| ASGI Server | uvicorn | Production server |
| CORS | FastAPI middleware | Cross-origin requests |

### DevOps Pipeline

| Stage | Technology | Purpose |
|-------|------------|---------|
| Containerization | Docker | Isolated environments |
| Orchestration | docker-compose | Multi-container management |
| Frontend Server | nginx | Static file serving |
| Reverse Proxy | nginx | API routing |
| Volume Management | Docker volumes | Persistent storage |

---

## ğŸ“ˆ Performance Metrics

### Pipeline Benchmarks

| Operation | Time | Notes |
|-----------|------|-------|
| CSV Parse (3451 points) | ~50ms | Papa Parse |
| Chart Render | ~100ms | Chart.js initial |
| Chart Update | ~16ms | 60 FPS target |
| AI Analysis | 2-5s | Gemini API latency |
| Chat Response | 1-3s | Depends on context |
| Graph Export (PNG) | ~200ms/graph | Matplotlib |
| ZIP Creation (10 graphs) | ~1s | Python zipfile |
| Database Query | <10ms | Indexed lookups |
| Login/Signup | ~150ms | bcrypt hashing |

---

## ğŸ”’ Security Pipeline

### Authentication Flow

```
1. Password Input
   â†“
2. Frontend validation (length, complexity)
   â†“
3. HTTPS transmission
   â†“
4. Backend receives plaintext password
   â†“
5. bcrypt.hashpw(password, bcrypt.gensalt(12))
   â†“
6. Store hash (never plaintext)
   â†“
7. Generate UUID session_id
   â†“
8. Store in sessions table with expiration
   â†“
9. Set httpOnly, secure cookie
   â†“
10. Frontend receives auth state (no password)
```

### Request Authorization

```
Every protected API call:
    â†“
    Include session cookie
    â†“
    @require_auth decorator validates:
      â”œâ”€ Cookie exists?
      â”œâ”€ Session in database?
      â”œâ”€ Session expired?
      â””â”€ User still exists?
    â†“
    If all checks pass: Proceed
    â†“
    If any fails: 401 Unauthorized
```

---

## ğŸ“¦ Deliverables Pipeline

### Development â†’ Production

```
1. LOCAL DEVELOPMENT
   â”œâ”€ npm run dev (Frontend: Vite dev server)
   â”œâ”€ uvicorn --reload (Backend: Hot reload)
   â””â”€ MySQL local instance

2. TESTING
   â”œâ”€ Frontend: Vitest unit tests
   â”œâ”€ Backend: pytest integration tests
   â””â”€ Manual QA testing

3. BUILD
   â”œâ”€ npm run build (Frontend: Optimized bundle)
   â”œâ”€ Docker build (Multi-stage builds)
   â””â”€ Image optimization

4. DEPLOYMENT
   â”œâ”€ docker-compose up -d (Production mode)
   â”œâ”€ nginx serves static files
   â”œâ”€ uvicorn workers: 4 processes
   â””â”€ MySQL persistent volumes

5. MONITORING
   â”œâ”€ Application logs
   â”œâ”€ Error tracking
   â””â”€ Performance metrics
```

---

## ğŸ¯ Future Pipeline Enhancements

### Planned Features

1. **Real-time Collaboration**
   ```
   User A uploads graphs
       â†“
   WebSocket broadcast to team
       â†“
   User B sees live updates
       â†“
   Collaborative annotations
   ```

2. **Batch Processing**
   ```
   Upload 100 samples
       â†“
   Queue processing jobs
       â†“
   Background worker pool
       â†“
   Progress notifications
       â†“
   Email when complete
   ```

3. **Advanced Analytics**
   ```
   Historical data trends
       â†“
   Predictive modeling with ML
       â†“
   Anomaly detection alerts
       â†“
   Automated reporting
   ```

4. **Cloud Storage**
   ```
   Export to cloud providers
       â†“
   AWS S3 / Google Cloud Storage
       â†“
   Shareable links
       â†“
   Long-term archival
   ```

---

## ğŸ“š Related Documentation

- **[README.md](README.md)** - Project overview
- **[API_DOCUMENTATION.md](API_DOCUMENTATION.md)** - API endpoints
- **[AUTH_DOCUMENTATION.md](AUTH_DOCUMENTATION.md)** - Authentication details
- **[FTIR_SCORING_METHODOLOGY.md](FTIR_SCORING_METHODOLOGY.md)** - Scoring algorithms
- **[SETUP_GUIDE.md](SETUP_GUIDE.md)** - Installation instructions

---

**Last Updated:** December 1, 2025  
**Version:** 1.0  
**Maintained by:** MRG Labs Development Team
